{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rH1tFALY35m",
        "outputId": "851a92f7-09fa-465e-aaed-4d310844215a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.13.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYR8bp4SY42O",
        "outputId": "ad4484db-9e3e-4c4b-d9fc-1a261e768b04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Downlaoding dataset"
      ],
      "metadata": {
        "id": "GDTN4AQDPqRE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT8y2DR5Wvrw",
        "outputId": "a3256419-c400-4774-fb73-a0136e996c82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-14 03:46:47--  https://drive.google.com/uc?export=download&id=1upXO4eN0dP8qKb0LL9hxS-J13BpHl7Dk\n",
            "Resolving drive.google.com (drive.google.com)... 142.251.8.138, 142.251.8.102, 142.251.8.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.251.8.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-10-18-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/o9g8jjfkqkrej8d7447f9ea7ctgvnc7r/1639453575000/14724390508833084599/*/1upXO4eN0dP8qKb0LL9hxS-J13BpHl7Dk?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-12-14 03:46:51--  https://doc-10-18-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/o9g8jjfkqkrej8d7447f9ea7ctgvnc7r/1639453575000/14724390508833084599/*/1upXO4eN0dP8qKb0LL9hxS-J13BpHl7Dk?e=download\n",
            "Resolving doc-10-18-docs.googleusercontent.com (doc-10-18-docs.googleusercontent.com)... 142.251.8.132, 2404:6800:4008:c15::84\n",
            "Connecting to doc-10-18-docs.googleusercontent.com (doc-10-18-docs.googleusercontent.com)|142.251.8.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19738266 (19M) [text/csv]\n",
            "Saving to: ‘tweets_combined.csv’\n",
            "\n",
            "tweets_combined.csv 100%[===================>]  18.82M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-12-14 03:46:51 (168 MB/s) - ‘tweets_combined.csv’ saved [19738266/19738266]\n",
            "\n",
            "--2021-12-14 03:46:51--  https://drive.google.com/uc?export=download&id=1nPww8vxj9NDO1ddVce-PM3F4y3bD59Pl\n",
            "Resolving drive.google.com (drive.google.com)... 142.251.8.139, 142.251.8.113, 142.251.8.102, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.251.8.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0g-18-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/45qg4ubm6aq2oeu3iq48as43ceevlven/1639453575000/14724390508833084599/*/1nPww8vxj9NDO1ddVce-PM3F4y3bD59Pl?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-12-14 03:46:53--  https://doc-0g-18-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/45qg4ubm6aq2oeu3iq48as43ceevlven/1639453575000/14724390508833084599/*/1nPww8vxj9NDO1ddVce-PM3F4y3bD59Pl?e=download\n",
            "Resolving doc-0g-18-docs.googleusercontent.com (doc-0g-18-docs.googleusercontent.com)... 142.251.8.132, 2404:6800:4008:c15::84\n",
            "Connecting to doc-0g-18-docs.googleusercontent.com (doc-0g-18-docs.googleusercontent.com)|142.251.8.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7752779 (7.4M) [text/csv]\n",
            "Saving to: ‘price_combined.csv’\n",
            "\n",
            "price_combined.csv  100%[===================>]   7.39M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-12-14 03:46:53 (183 MB/s) - ‘price_combined.csv’ saved [7752779/7752779]\n",
            "\n",
            "--2021-12-14 03:46:53--  https://drive.google.com/uc?export=download&id=1ka75BqQ65SPxD-zr8goJIzoKmLLw09Uw\n",
            "Resolving drive.google.com (drive.google.com)... 142.251.8.139, 142.251.8.100, 142.251.8.101, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.251.8.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘uc?export=download&id=1ka75BqQ65SPxD-zr8goJIzoKmLLw09Uw’\n",
            "\n",
            "uc?export=download&     [ <=>                ]   3.22K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-14 03:46:53 (60.6 MB/s) - ‘uc?export=download&id=1ka75BqQ65SPxD-zr8goJIzoKmLLw09Uw’ saved [3302]\n",
            "\n",
            "--2021-12-14 03:46:53--  https://drive.google.com/uc?export=download&confirm=CGXa&id=1ka75BqQ65SPxD-zr8goJIzoKmLLw09Uw\n",
            "Reusing existing connection to drive.google.com:443.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0g-9g-docs.googleusercontent.com/docs/securesc/dkpltbnmp3b8j1s4rnmc4onmpnh4p7nm/arko7ctr7got7fo5g5l10obtgnndrfur/1639453575000/14724390508833084599/18369196090772553889Z/1ka75BqQ65SPxD-zr8goJIzoKmLLw09Uw?e=download [following]\n",
            "--2021-12-14 03:46:54--  https://doc-0g-9g-docs.googleusercontent.com/docs/securesc/dkpltbnmp3b8j1s4rnmc4onmpnh4p7nm/arko7ctr7got7fo5g5l10obtgnndrfur/1639453575000/14724390508833084599/18369196090772553889Z/1ka75BqQ65SPxD-zr8goJIzoKmLLw09Uw?e=download\n",
            "Resolving doc-0g-9g-docs.googleusercontent.com (doc-0g-9g-docs.googleusercontent.com)... 142.251.8.132, 2404:6800:4008:c15::84\n",
            "Connecting to doc-0g-9g-docs.googleusercontent.com (doc-0g-9g-docs.googleusercontent.com)|142.251.8.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=i4tiatqcvr59u&continue=https://doc-0g-9g-docs.googleusercontent.com/docs/securesc/dkpltbnmp3b8j1s4rnmc4onmpnh4p7nm/arko7ctr7got7fo5g5l10obtgnndrfur/1639453575000/14724390508833084599/18369196090772553889Z/1ka75BqQ65SPxD-zr8goJIzoKmLLw09Uw?e%3Ddownload&hash=untn53bcj5i4jdrf72skcgc6siib9aph [following]\n",
            "--2021-12-14 03:46:54--  https://docs.google.com/nonceSigner?nonce=i4tiatqcvr59u&continue=https://doc-0g-9g-docs.googleusercontent.com/docs/securesc/dkpltbnmp3b8j1s4rnmc4onmpnh4p7nm/arko7ctr7got7fo5g5l10obtgnndrfur/1639453575000/14724390508833084599/18369196090772553889Z/1ka75BqQ65SPxD-zr8goJIzoKmLLw09Uw?e%3Ddownload&hash=untn53bcj5i4jdrf72skcgc6siib9aph\n",
            "Resolving docs.google.com (docs.google.com)... 64.233.189.101, 64.233.189.139, 64.233.189.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|64.233.189.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-0g-9g-docs.googleusercontent.com/docs/securesc/dkpltbnmp3b8j1s4rnmc4onmpnh4p7nm/arko7ctr7got7fo5g5l10obtgnndrfur/1639453575000/14724390508833084599/18369196090772553889Z/1ka75BqQ65SPxD-zr8goJIzoKmLLw09Uw?e=download&nonce=i4tiatqcvr59u&user=18369196090772553889Z&hash=md2bf7b546e950c6bcv6acn6ad26obht [following]\n",
            "--2021-12-14 03:46:55--  https://doc-0g-9g-docs.googleusercontent.com/docs/securesc/dkpltbnmp3b8j1s4rnmc4onmpnh4p7nm/arko7ctr7got7fo5g5l10obtgnndrfur/1639453575000/14724390508833084599/18369196090772553889Z/1ka75BqQ65SPxD-zr8goJIzoKmLLw09Uw?e=download&nonce=i4tiatqcvr59u&user=18369196090772553889Z&hash=md2bf7b546e950c6bcv6acn6ad26obht\n",
            "Connecting to doc-0g-9g-docs.googleusercontent.com (doc-0g-9g-docs.googleusercontent.com)|142.251.8.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 238803811 (228M) [text/csv]\n",
            "Saving to: ‘uc?export=download&confirm=CGXa&id=1ka75BqQ65SPxD-zr8goJIzoKmLLw09Uw’\n",
            "\n",
            "uc?export=download& 100%[===================>] 227.74M   196MB/s    in 1.2s    \n",
            "\n",
            "2021-12-14 03:46:56 (196 MB/s) - ‘uc?export=download&confirm=CGXa&id=1ka75BqQ65SPxD-zr8goJIzoKmLLw09Uw’ saved [238803811/238803811]\n",
            "\n",
            "FINISHED --2021-12-14 03:46:56--\n",
            "Total wall clock time: 3.4s\n",
            "Downloaded: 2 files, 228M in 1.2s (196 MB/s)\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1upXO4eN0dP8qKb0LL9hxS-J13BpHl7Dk' -O 'tweets_combined.csv'\n",
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1nPww8vxj9NDO1ddVce-PM3F4y3bD59Pl' -O 'price_combined.csv'\n",
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1ka75BqQ65SPxD-zr8goJIzoKmLLw09Uw' -r -A 'uc*' -e robots=off -nd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTNc7P7AW_Al",
        "outputId": "a1f9a8f6-9d7d-41cc-8d52-3c60828e396e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " price_combined.csv\n",
            " sample_data\n",
            " tweets_combined.csv\n",
            " twitter_sentiment_dataset.csv\n",
            " twitter_test.csv\n",
            " twitter_train.csv\n",
            "'uc?export=download&confirm=CGXa&id=1ka75BqQ65SPxD-zr8goJIzoKmLLw09Uw'\n",
            "'uc?export=download&id=1ka75BqQ65SPxD-zr8goJIzoKmLLw09Uw'\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Please copy paste the link starting with 'uc?export=download&confirm= ' in the next line to proceed with the implementation."
      ],
      "metadata": {
        "id": "0tbXOuwDvZ9M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeKOAOfiXBYY"
      },
      "outputs": [],
      "source": [
        "!mv 'uc?export=download&confirm=bTwH&id=1ka75BqQ65SPxD-zr8goJIzoKmLLw09Uw' 'twitter_sentiment_dataset.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjXTMNC8ZuPX",
        "outputId": "bc14df33-34b7-4b11-bf3b-fa2bb7557c6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price_combined.csv  tweets_combined.csv\n",
            "sample_data\t    twitter_sentiment_dataset.csv\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_BjoFmgXFcR",
        "outputId": "76901a2c-8112-4d70-b6cc-6a3d9c2763cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTqWSTziXGab",
        "outputId": "9a7371a8-7579-4353-de25-ad9504ed974a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICgI-TozXGX6",
        "outputId": "3fc07bd2-d263-4512-8fb3-57e5a1fb8ad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAC4f2gfXGVk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "%matplotlib inline\n",
        "sns.set(color_codes=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('twitter_sentiment_dataset.csv', encoding='latin-1', header = None)\n",
        "df.columns=['Sentiment', 'id', 'Date', 'Query', 'User', 'Tweet']\n",
        "df = df.drop(columns=['id', 'Date', 'Query', 'User'], axis=1)"
      ],
      "metadata": {
        "id": "x1L3X_5Vv4Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "WNsDWecFv4Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df.Sentiment)"
      ],
      "metadata": {
        "id": "3r6_oUE4v32k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sentiment'] = df.Sentiment.replace(4,1)"
      ],
      "metadata": {
        "id": "ATwsv2K-v3xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df.Sentiment)"
      ],
      "metadata": {
        "id": "p5UbuqR1wH-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "hashtags = re.compile(r\"^#\\S+|\\s#\\S+\")\n",
        "mentions = re.compile(r\"^@\\S+|\\s@\\S+\")\n",
        "urls = re.compile(r\"https?://\\S+\")\n",
        "\n",
        "def process_text(text):\n",
        "    text = re.sub(r'http\\S+', 'URL', text)\n",
        "    text = hashtags.sub(' ', text)\n",
        "    text = mentions.sub('AT_USER', text)\n",
        "    return text.strip().lower()"
      ],
      "metadata": {
        "id": "tLU2Ff37wPpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Tweet'] = df.Tweet.apply(process_text)"
      ],
      "metadata": {
        "id": "uly2XQgEwX6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "UogHqZx3waUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=1)"
      ],
      "metadata": {
        "id": "7TCxIOfPFPzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df, test_size=0.2)"
      ],
      "metadata": {
        "id": "aoMtdZWFxAqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.to_csv('twitter_test.csv',index=False)"
      ],
      "metadata": {
        "id": "HUKrTGrTyvPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPjlQC9jXd9J"
      },
      "outputs": [],
      "source": [
        "labels = train.Sentiment.values\n",
        "sentences = train.Tweet.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hrP2GtvXouF",
        "outputId": "a80218be-f19e-4860-b1af-f9cad671053d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_x35SDHXorQ",
        "outputId": "eb83d3dd-285b-4e46-9572-e53c4a309305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  fuck why is my cable broken all of the sudden\n",
            "Tokenized:  ['fuck', 'why', 'is', 'my', 'cable', 'broken', 'all', 'of', 'the', 'sudden']\n",
            "Token IDs:  [6616, 2339, 2003, 2026, 5830, 3714, 2035, 1997, 1996, 5573]\n"
          ]
        }
      ],
      "source": [
        "print(' Original: ', sentences[0])\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDNwomVFXooe",
        "outputId": "eb5e90dd-f044-4ac4-8064-492fb1ff55aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  fuck why is my cable broken all of the sudden\n",
            "Token IDs: tensor([ 101, 6616, 2339, 2003, 2026, 5830, 3714, 2035, 1997, 1996, 5573,  102,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0])\n"
          ]
        }
      ],
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 64,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yULqMOdMXoTb",
        "outputId": "ecf9341a-2975-44fc-b5d1-40f9e6186ad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1,293,487 training samples\n",
            "143,721 validation samples\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCyehMzRX2rz"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset,\n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3nof5SQX4tB",
        "outputId": "7e8f18c4-53d8-44a1-9382-3192a2a6f866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = 2,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wgq61kNfa7ir"
      },
      "outputs": [],
      "source": [
        "def bert_base_adamw_llrd(model):\n",
        "    \n",
        "    opt_parameters = []\n",
        "    named_parameters = list(model.named_parameters()) \n",
        "\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    init_lr = 3.5e-6 \n",
        "    head_lr = 3.6e-6\n",
        "    lr = init_lr\n",
        "    \n",
        "    params_0 = [p for n,p in named_parameters if (\"pooler\" in n or \"regressor\" in n) \n",
        "                and any(nd in n for nd in no_decay)]\n",
        "    params_1 = [p for n,p in named_parameters if (\"pooler\" in n or \"regressor\" in n)\n",
        "                and not any(nd in n for nd in no_decay)]\n",
        "    \n",
        "    head_params = {\"params\": params_0, \"lr\": head_lr, \"weight_decay\": 0.0}    \n",
        "    opt_parameters.append(head_params)\n",
        "        \n",
        "    head_params = {\"params\": params_1, \"lr\": head_lr, \"weight_decay\": 0.01}    \n",
        "    opt_parameters.append(head_params)\n",
        "\n",
        "    for layer in range(11,-1,-1):        \n",
        "        params_0 = [p for n,p in named_parameters if f\"encoder.layer.{layer}.\" in n \n",
        "                    and any(nd in n for nd in no_decay)]\n",
        "        params_1 = [p for n,p in named_parameters if f\"encoder.layer.{layer}.\" in n \n",
        "                    and not any(nd in n for nd in no_decay)]\n",
        "        \n",
        "        layer_params = {\"params\": params_0, \"lr\": lr, \"weight_decay\": 0.0}\n",
        "        opt_parameters.append(layer_params)   \n",
        "                            \n",
        "        layer_params = {\"params\": params_1, \"lr\": lr, \"weight_decay\": 0.01}\n",
        "        opt_parameters.append(layer_params)       \n",
        "        \n",
        "        lr *= 0.9     \n",
        "    \n",
        "    params_0 = [p for n,p in named_parameters if \"embeddings\" in n \n",
        "                and any(nd in n for nd in no_decay)]\n",
        "    params_1 = [p for n,p in named_parameters if \"embeddings\" in n\n",
        "                and not any(nd in n for nd in no_decay)]\n",
        "    \n",
        "    embed_params = {\"params\": params_0, \"lr\": lr, \"weight_decay\": 0.0} \n",
        "    opt_parameters.append(embed_params)\n",
        "        \n",
        "    embed_params = {\"params\": params_1, \"lr\": lr, \"weight_decay\": 0.01} \n",
        "    opt_parameters.append(embed_params)        \n",
        "    \n",
        "    return AdamW(opt_parameters, lr=init_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrEVfoePb-G6"
      },
      "outputs": [],
      "source": [
        "optimizer = bert_base_adamw_llrd(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsNREbtCX4gh"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 1\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 50,\n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXu72aA_X4dc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxRlTA5ZYI20"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ahsmXapYLT-",
        "outputId": "0bde8fb5-181d-4259-f032-fa32c555dfcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 1 ========\n",
            "Training...\n",
            "  Batch   500  of  80,843.    Elapsed: 0:01:02.\n",
            "  Batch 1,000  of  80,843.    Elapsed: 0:02:05.\n",
            "  Batch 1,500  of  80,843.    Elapsed: 0:03:07.\n",
            "  Batch 2,000  of  80,843.    Elapsed: 0:04:09.\n",
            "  Batch 2,500  of  80,843.    Elapsed: 0:05:11.\n",
            "  Batch 3,000  of  80,843.    Elapsed: 0:06:14.\n",
            "  Batch 3,500  of  80,843.    Elapsed: 0:07:16.\n",
            "  Batch 4,000  of  80,843.    Elapsed: 0:08:18.\n",
            "  Batch 4,500  of  80,843.    Elapsed: 0:09:21.\n",
            "  Batch 5,000  of  80,843.    Elapsed: 0:10:23.\n",
            "  Batch 5,500  of  80,843.    Elapsed: 0:11:25.\n",
            "  Batch 6,000  of  80,843.    Elapsed: 0:12:28.\n",
            "  Batch 6,500  of  80,843.    Elapsed: 0:13:30.\n",
            "  Batch 7,000  of  80,843.    Elapsed: 0:14:32.\n",
            "  Batch 7,500  of  80,843.    Elapsed: 0:15:34.\n",
            "  Batch 8,000  of  80,843.    Elapsed: 0:16:36.\n",
            "  Batch 8,500  of  80,843.    Elapsed: 0:17:39.\n",
            "  Batch 9,000  of  80,843.    Elapsed: 0:18:41.\n",
            "  Batch 9,500  of  80,843.    Elapsed: 0:19:43.\n",
            "  Batch 10,000  of  80,843.    Elapsed: 0:20:45.\n",
            "  Batch 10,500  of  80,843.    Elapsed: 0:21:47.\n",
            "  Batch 11,000  of  80,843.    Elapsed: 0:22:50.\n",
            "  Batch 11,500  of  80,843.    Elapsed: 0:23:52.\n",
            "  Batch 12,000  of  80,843.    Elapsed: 0:24:54.\n",
            "  Batch 12,500  of  80,843.    Elapsed: 0:25:56.\n",
            "  Batch 13,000  of  80,843.    Elapsed: 0:26:58.\n",
            "  Batch 13,500  of  80,843.    Elapsed: 0:28:01.\n",
            "  Batch 14,000  of  80,843.    Elapsed: 0:29:03.\n",
            "  Batch 14,500  of  80,843.    Elapsed: 0:30:05.\n",
            "  Batch 15,000  of  80,843.    Elapsed: 0:31:07.\n",
            "  Batch 15,500  of  80,843.    Elapsed: 0:32:09.\n",
            "  Batch 16,000  of  80,843.    Elapsed: 0:33:12.\n",
            "  Batch 16,500  of  80,843.    Elapsed: 0:34:14.\n",
            "  Batch 17,000  of  80,843.    Elapsed: 0:35:16.\n",
            "  Batch 17,500  of  80,843.    Elapsed: 0:36:18.\n",
            "  Batch 18,000  of  80,843.    Elapsed: 0:37:21.\n",
            "  Batch 18,500  of  80,843.    Elapsed: 0:38:23.\n",
            "  Batch 19,000  of  80,843.    Elapsed: 0:39:25.\n",
            "  Batch 19,500  of  80,843.    Elapsed: 0:40:27.\n",
            "  Batch 20,000  of  80,843.    Elapsed: 0:41:29.\n",
            "  Batch 20,500  of  80,843.    Elapsed: 0:42:31.\n",
            "  Batch 21,000  of  80,843.    Elapsed: 0:43:34.\n",
            "  Batch 21,500  of  80,843.    Elapsed: 0:44:36.\n",
            "  Batch 22,000  of  80,843.    Elapsed: 0:45:38.\n",
            "  Batch 22,500  of  80,843.    Elapsed: 0:46:41.\n",
            "  Batch 23,000  of  80,843.    Elapsed: 0:47:43.\n",
            "  Batch 23,500  of  80,843.    Elapsed: 0:48:45.\n",
            "  Batch 24,000  of  80,843.    Elapsed: 0:49:47.\n",
            "  Batch 24,500  of  80,843.    Elapsed: 0:50:49.\n",
            "  Batch 25,000  of  80,843.    Elapsed: 0:51:52.\n",
            "  Batch 25,500  of  80,843.    Elapsed: 0:52:54.\n",
            "  Batch 26,000  of  80,843.    Elapsed: 0:53:56.\n",
            "  Batch 26,500  of  80,843.    Elapsed: 0:54:58.\n",
            "  Batch 27,000  of  80,843.    Elapsed: 0:56:01.\n",
            "  Batch 27,500  of  80,843.    Elapsed: 0:57:03.\n",
            "  Batch 28,000  of  80,843.    Elapsed: 0:58:05.\n",
            "  Batch 28,500  of  80,843.    Elapsed: 0:59:07.\n",
            "  Batch 29,000  of  80,843.    Elapsed: 1:00:10.\n",
            "  Batch 29,500  of  80,843.    Elapsed: 1:01:12.\n",
            "  Batch 30,000  of  80,843.    Elapsed: 1:02:14.\n",
            "  Batch 30,500  of  80,843.    Elapsed: 1:03:16.\n",
            "  Batch 31,000  of  80,843.    Elapsed: 1:04:19.\n",
            "  Batch 31,500  of  80,843.    Elapsed: 1:05:21.\n",
            "  Batch 32,000  of  80,843.    Elapsed: 1:06:23.\n",
            "  Batch 32,500  of  80,843.    Elapsed: 1:07:25.\n",
            "  Batch 33,000  of  80,843.    Elapsed: 1:08:27.\n",
            "  Batch 33,500  of  80,843.    Elapsed: 1:09:30.\n",
            "  Batch 34,000  of  80,843.    Elapsed: 1:10:32.\n",
            "  Batch 34,500  of  80,843.    Elapsed: 1:11:34.\n",
            "  Batch 35,000  of  80,843.    Elapsed: 1:12:36.\n",
            "  Batch 35,500  of  80,843.    Elapsed: 1:13:39.\n",
            "  Batch 36,000  of  80,843.    Elapsed: 1:14:41.\n",
            "  Batch 36,500  of  80,843.    Elapsed: 1:15:43.\n",
            "  Batch 37,000  of  80,843.    Elapsed: 1:16:46.\n",
            "  Batch 37,500  of  80,843.    Elapsed: 1:17:48.\n",
            "  Batch 38,000  of  80,843.    Elapsed: 1:18:50.\n",
            "  Batch 38,500  of  80,843.    Elapsed: 1:19:52.\n",
            "  Batch 39,000  of  80,843.    Elapsed: 1:20:54.\n",
            "  Batch 39,500  of  80,843.    Elapsed: 1:21:57.\n",
            "  Batch 40,000  of  80,843.    Elapsed: 1:22:59.\n",
            "  Batch 40,500  of  80,843.    Elapsed: 1:24:01.\n",
            "  Batch 41,000  of  80,843.    Elapsed: 1:25:03.\n",
            "  Batch 41,500  of  80,843.    Elapsed: 1:26:06.\n",
            "  Batch 42,000  of  80,843.    Elapsed: 1:27:08.\n",
            "  Batch 42,500  of  80,843.    Elapsed: 1:28:10.\n",
            "  Batch 43,000  of  80,843.    Elapsed: 1:29:13.\n",
            "  Batch 43,500  of  80,843.    Elapsed: 1:30:15.\n",
            "  Batch 44,000  of  80,843.    Elapsed: 1:31:17.\n",
            "  Batch 44,500  of  80,843.    Elapsed: 1:32:20.\n",
            "  Batch 45,000  of  80,843.    Elapsed: 1:33:22.\n",
            "  Batch 45,500  of  80,843.    Elapsed: 1:34:24.\n",
            "  Batch 46,000  of  80,843.    Elapsed: 1:35:27.\n",
            "  Batch 46,500  of  80,843.    Elapsed: 1:36:29.\n",
            "  Batch 47,000  of  80,843.    Elapsed: 1:37:31.\n",
            "  Batch 47,500  of  80,843.    Elapsed: 1:38:34.\n",
            "  Batch 48,000  of  80,843.    Elapsed: 1:39:36.\n",
            "  Batch 48,500  of  80,843.    Elapsed: 1:40:38.\n",
            "  Batch 49,000  of  80,843.    Elapsed: 1:41:40.\n",
            "  Batch 49,500  of  80,843.    Elapsed: 1:42:43.\n",
            "  Batch 50,000  of  80,843.    Elapsed: 1:43:45.\n",
            "  Batch 50,500  of  80,843.    Elapsed: 1:44:47.\n",
            "  Batch 51,000  of  80,843.    Elapsed: 1:45:49.\n",
            "  Batch 51,500  of  80,843.    Elapsed: 1:46:52.\n",
            "  Batch 52,000  of  80,843.    Elapsed: 1:47:54.\n",
            "  Batch 52,500  of  80,843.    Elapsed: 1:48:56.\n",
            "  Batch 53,000  of  80,843.    Elapsed: 1:49:59.\n",
            "  Batch 53,500  of  80,843.    Elapsed: 1:51:01.\n",
            "  Batch 54,000  of  80,843.    Elapsed: 1:52:03.\n",
            "  Batch 54,500  of  80,843.    Elapsed: 1:53:06.\n",
            "  Batch 55,000  of  80,843.    Elapsed: 1:54:08.\n",
            "  Batch 55,500  of  80,843.    Elapsed: 1:55:10.\n",
            "  Batch 56,000  of  80,843.    Elapsed: 1:56:13.\n",
            "  Batch 56,500  of  80,843.    Elapsed: 1:57:15.\n",
            "  Batch 57,000  of  80,843.    Elapsed: 1:58:17.\n",
            "  Batch 57,500  of  80,843.    Elapsed: 1:59:20.\n",
            "  Batch 58,000  of  80,843.    Elapsed: 2:00:22.\n",
            "  Batch 58,500  of  80,843.    Elapsed: 2:01:25.\n",
            "  Batch 59,000  of  80,843.    Elapsed: 2:02:27.\n",
            "  Batch 59,500  of  80,843.    Elapsed: 2:03:29.\n",
            "  Batch 60,000  of  80,843.    Elapsed: 2:04:32.\n",
            "  Batch 60,500  of  80,843.    Elapsed: 2:05:34.\n",
            "  Batch 61,000  of  80,843.    Elapsed: 2:06:36.\n",
            "  Batch 61,500  of  80,843.    Elapsed: 2:07:38.\n",
            "  Batch 62,000  of  80,843.    Elapsed: 2:08:41.\n",
            "  Batch 62,500  of  80,843.    Elapsed: 2:09:43.\n",
            "  Batch 63,000  of  80,843.    Elapsed: 2:10:45.\n",
            "  Batch 63,500  of  80,843.    Elapsed: 2:11:47.\n",
            "  Batch 64,000  of  80,843.    Elapsed: 2:12:49.\n",
            "  Batch 64,500  of  80,843.    Elapsed: 2:13:52.\n",
            "  Batch 65,000  of  80,843.    Elapsed: 2:14:54.\n",
            "  Batch 65,500  of  80,843.    Elapsed: 2:15:56.\n",
            "  Batch 66,000  of  80,843.    Elapsed: 2:16:59.\n",
            "  Batch 66,500  of  80,843.    Elapsed: 2:18:01.\n",
            "  Batch 67,000  of  80,843.    Elapsed: 2:19:03.\n",
            "  Batch 67,500  of  80,843.    Elapsed: 2:20:06.\n",
            "  Batch 68,000  of  80,843.    Elapsed: 2:21:08.\n",
            "  Batch 68,500  of  80,843.    Elapsed: 2:22:10.\n",
            "  Batch 69,000  of  80,843.    Elapsed: 2:23:13.\n",
            "  Batch 69,500  of  80,843.    Elapsed: 2:24:15.\n",
            "  Batch 70,000  of  80,843.    Elapsed: 2:25:18.\n",
            "  Batch 70,500  of  80,843.    Elapsed: 2:26:20.\n",
            "  Batch 71,000  of  80,843.    Elapsed: 2:27:22.\n",
            "  Batch 71,500  of  80,843.    Elapsed: 2:28:25.\n",
            "  Batch 72,000  of  80,843.    Elapsed: 2:29:27.\n",
            "  Batch 72,500  of  80,843.    Elapsed: 2:30:29.\n",
            "  Batch 73,000  of  80,843.    Elapsed: 2:31:32.\n",
            "  Batch 73,500  of  80,843.    Elapsed: 2:32:34.\n",
            "  Batch 74,000  of  80,843.    Elapsed: 2:33:36.\n",
            "  Batch 74,500  of  80,843.    Elapsed: 2:34:39.\n",
            "  Batch 75,000  of  80,843.    Elapsed: 2:35:41.\n",
            "  Batch 75,500  of  80,843.    Elapsed: 2:36:43.\n",
            "  Batch 76,000  of  80,843.    Elapsed: 2:37:45.\n",
            "  Batch 76,500  of  80,843.    Elapsed: 2:38:48.\n",
            "  Batch 77,000  of  80,843.    Elapsed: 2:39:50.\n",
            "  Batch 77,500  of  80,843.    Elapsed: 2:40:52.\n",
            "  Batch 78,000  of  80,843.    Elapsed: 2:41:55.\n",
            "  Batch 78,500  of  80,843.    Elapsed: 2:42:57.\n",
            "  Batch 79,000  of  80,843.    Elapsed: 2:43:59.\n",
            "  Batch 79,500  of  80,843.    Elapsed: 2:45:01.\n",
            "  Batch 80,000  of  80,843.    Elapsed: 2:46:03.\n",
            "  Batch 80,500  of  80,843.    Elapsed: 2:47:05.\n",
            "\n",
            "  Average training loss: 0.35\n",
            "  Training epoch took: 2:47:48\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.33\n",
            "  Validation took: 0:05:06\n",
            "\n",
            "Training complete!\n",
            "Total training took 2:52:54 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 8\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        model.zero_grad()\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "        total_eval_loss += loss.item()\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "fU43U-7bYLPB",
        "outputId": "b15eaa3a-cce5-41dc-a834-207c85dea5a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.35</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.86</td>\n",
              "      <td>2:47:48</td>\n",
              "      <td>0:05:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.35         0.33           0.86       2:47:48         0:05:06"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.set_option('precision', 2)\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "df_stats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"twitter_test.csv\")\n",
        "df = df.dropna()\n",
        "\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "sentences = df.Tweet.values\n",
        "labels = df.Sentiment.values\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 64,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                   )\n",
        " \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "batch_size = 32  \n",
        "prediction_data = TensorDataset(input_ids, attention_masks,labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dNaGhfda-lA",
        "outputId": "a23c4ab9-527b-4080-f603-a80f6cba3c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test sentences: 159,704\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "predictions ,predictions_probs, true_labels = [], [], []\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask,b_labels = batch\n",
        "  with torch.no_grad():\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "  probabilities = F.softmax(logits, dim=1)\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  probabilities = probabilities.detach().cpu().numpy()\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "  predictions_probs.append(probabilities)\n",
        "\n",
        "print('    DONE.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWotlgdwa-h_",
        "outputId": "a926d24a-6239-4a4a-b197-9d49f6ea1b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 159,704 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "flat_predictions_probs = np.concatenate(predictions_probs, axis=0)\n",
        "\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "avg_test_accuracy = np.sum(flat_predictions == flat_true_labels) / len(flat_true_labels)\n",
        "\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_test_accuracy))\n",
        "print(flat_predictions[10],flat_true_labels[10],flat_predictions_probs[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQmdbfpkomt8",
        "outputId": "8e260d06-9a32-478d-843f-89ea1e9fd27c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Accuracy: 0.86\n",
            "0 0 [0.99167085 0.00832917]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(flat_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd-DTbWYjuAG",
        "outputId": "f1b2a524-93b5-4471-e65c-6e7622917d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = list(flat_predictions)"
      ],
      "metadata": {
        "id": "31-p3mWNjc1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_output = pd.DataFrame(list(zip(list(flat_predictions), list(flat_true_labels),list(flat_predictions_probs))),columns = ['predictions','true_labels','pred_probs'])"
      ],
      "metadata": {
        "id": "nIGzgK5rjaFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_output[df_output['predictions']==0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "fMLZuvnwkaqX",
        "outputId": "1f75e85b-f24f-4ead-858e-f13eeac0a9f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predictions</th>\n",
              "      <th>true_labels</th>\n",
              "      <th>pred_probs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.9886778, 0.01132213]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.9790299, 0.020970104]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.9965725, 0.0034275427]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.93998504, 0.060014993]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.98344064, 0.01655942]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159694</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.9955395, 0.0044605345]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159695</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.5669716, 0.43302837]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159697</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.8787022, 0.12129773]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159698</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.8672617, 0.13273834]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159700</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.9841517, 0.015848253]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80881 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        predictions  true_labels                 pred_probs\n",
              "2                 0            0    [0.9886778, 0.01132213]\n",
              "4                 0            0   [0.9790299, 0.020970104]\n",
              "7                 0            0  [0.9965725, 0.0034275427]\n",
              "8                 0            0  [0.93998504, 0.060014993]\n",
              "9                 0            0   [0.98344064, 0.01655942]\n",
              "...             ...          ...                        ...\n",
              "159694            0            0  [0.9955395, 0.0044605345]\n",
              "159695            0            1    [0.5669716, 0.43302837]\n",
              "159697            0            1    [0.8787022, 0.12129773]\n",
              "159698            0            0    [0.8672617, 0.13273834]\n",
              "159700            0            0   [0.9841517, 0.015848253]\n",
              "\n",
              "[80881 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_output = pd.merge(df,df_output,left_index=True,right_index=True,how='inner')"
      ],
      "metadata": {
        "id": "ZPiDxtPNze56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_output.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "o2V8Xh-BzyBU",
        "outputId": "35b9a7ee-66b6-43f6-90a5-79e9fa62f2c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>predictions</th>\n",
              "      <th>true_labels</th>\n",
              "      <th>pred_probs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>eating a banana - i also just fit into a size ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.026936928, 0.97306305]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>awesome! we had a lot of family time, too. tal...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.008765864, 0.9912341]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>eep. just had a waking nightmare. i don't know...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.9886778, 0.01132213]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>i'm thinking maybe i should raid the fridge n ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.10359162, 0.89640844]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>i miss you</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.9790299, 0.020970104]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentiment  ...                 pred_probs\n",
              "0          1  ...  [0.026936928, 0.97306305]\n",
              "1          1  ...   [0.008765864, 0.9912341]\n",
              "2          0  ...    [0.9886778, 0.01132213]\n",
              "3          1  ...   [0.10359162, 0.89640844]\n",
              "4          0  ...   [0.9790299, 0.020970104]\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_output.to_csv('df_test_output.csv',index=False)"
      ],
      "metadata": {
        "id": "iU372H9kz_zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"tweets_combined.csv\",encoding='latin-1',lineterminator='\\n')"
      ],
      "metadata": {
        "id": "UXR2ovCw01sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "YVuQqer91Fjt",
        "outputId": "caae561e-d2a2-4438-b03b-09ce3544932b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stock_symbol</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>time</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>583947352286875648</td>\n",
              "      <td>Fri Apr 03 11:01:12 +0000 2015</td>\n",
              "      <td>RT NewsSDRL: RT NewsSDRL: #toptickertweets $AA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>583948769961648128</td>\n",
              "      <td>Fri Apr 03 11:06:50 +0000 2015</td>\n",
              "      <td>RT NewsIACI: RT NewsIACI: RT NewsSDRL: #toptic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>583950963590897665</td>\n",
              "      <td>Fri Apr 03 11:15:33 +0000 2015</td>\n",
              "      <td>10 things in tech you need to know today $GOOG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>583952666491019264</td>\n",
              "      <td>Fri Apr 03 11:22:19 +0000 2015</td>\n",
              "      <td>RT NewsSDRL: RT NewsSDRL: #toptickertweets $AA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>583963546490404864</td>\n",
              "      <td>Fri Apr 03 12:05:33 +0000 2015</td>\n",
              "      <td>RT NewsIACI: RT NewsIACI: RT NewsAAPL: #toptic...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  stock_symbol  ...                                              tweet\n",
              "0         AAPL  ...  RT NewsSDRL: RT NewsSDRL: #toptickertweets $AA...\n",
              "1         AAPL  ...  RT NewsIACI: RT NewsIACI: RT NewsSDRL: #toptic...\n",
              "2         AAPL  ...  10 things in tech you need to know today $GOOG...\n",
              "3         AAPL  ...  RT NewsSDRL: RT NewsSDRL: #toptickertweets $AA...\n",
              "4         AAPL  ...  RT NewsIACI: RT NewsIACI: RT NewsAAPL: #toptic...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "hashtags = re.compile(r\"^#\\S+|\\s#\\S+\")\n",
        "mentions = re.compile(r\"^@\\S+|\\s@\\S+\")\n",
        "urls = re.compile(r\"https?://\\S+\")\n",
        "\n",
        "def process_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = hashtags.sub(' ', text)\n",
        "    text = mentions.sub(' ', text)\n",
        "    return text.strip().lower()"
      ],
      "metadata": {
        "id": "OAIn72l-1VND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tweet'] = df.tweet.apply(process_text)"
      ],
      "metadata": {
        "id": "uaN7NlpO1avW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "sentences = df.tweet.values\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 64,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                   )\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "batch_size = 32  \n",
        "prediction_data = TensorDataset(input_ids, attention_masks)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2RDNKzK0Sr-",
        "outputId": "af351e31-cff4-4a62-af8b-51dd5a259505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test sentences: 119,852\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "model.eval()\n",
        "predictions ,predictions_probs = [], []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  b_input_ids, b_input_mask = batch\n",
        "\n",
        "  with torch.no_grad():\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "  probabilities = F.softmax(logits, dim=1)\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  probabilities = probabilities.detach().cpu().numpy()\n",
        "  predictions.append(logits)\n",
        "  predictions_probs.append(probabilities)\n",
        "\n",
        "print('    DONE.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB-wacnE0Soo",
        "outputId": "7fdecdd9-c7be-420d-e584-2c7cdd874160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 119,852 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "flat_predictions_probs = np.concatenate(predictions_probs, axis=0)\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "print(flat_predictions[10],flat_predictions_probs[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlEDF8h50SlH",
        "outputId": "942ddb9a-a27e-4360-adce-dfeff7223fe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 [0.08424371 0.9157563 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_output = pd.DataFrame(list(zip(list(flat_predictions),list(flat_predictions_probs))),columns = ['predictions','pred_probs'])"
      ],
      "metadata": {
        "id": "aj79hhYF0Sh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_output = pd.merge(df,df_output,left_index=True,right_index=True,how='inner')"
      ],
      "metadata": {
        "id": "IXCJIqkp0SfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_output.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "XGFxYzc73WT5",
        "outputId": "2a3a6419-ad3f-4f73-8c88-2b0bbc98e75f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stock_symbol</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>time</th>\n",
              "      <th>tweet</th>\n",
              "      <th>predictions</th>\n",
              "      <th>pred_probs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>583947352286875648</td>\n",
              "      <td>Fri Apr 03 11:01:12 +0000 2015</td>\n",
              "      <td>rt newssdrl: rt newssdrl:  $aapl $spy $tza $ts...</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.40755036, 0.5924496]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>583948769961648128</td>\n",
              "      <td>Fri Apr 03 11:06:50 +0000 2015</td>\n",
              "      <td>rt newsiaci: rt newsiaci: rt newssdrl:  $aapl ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.39781833, 0.6021817]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>583950963590897665</td>\n",
              "      <td>Fri Apr 03 11:15:33 +0000 2015</td>\n",
              "      <td>10 things in tech you need to know today $goog...</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.09492045, 0.9050796]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>583952666491019264</td>\n",
              "      <td>Fri Apr 03 11:22:19 +0000 2015</td>\n",
              "      <td>rt newssdrl: rt newssdrl:  $aapl $spy $tza $ts...</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.40755036, 0.5924496]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>583963546490404864</td>\n",
              "      <td>Fri Apr 03 12:05:33 +0000 2015</td>\n",
              "      <td>rt newsiaci: rt newsiaci: rt newsaapl:  $aapl ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.424042, 0.575958]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  stock_symbol            tweet_id  ... predictions               pred_probs\n",
              "0         AAPL  583947352286875648  ...           1  [0.40755036, 0.5924496]\n",
              "1         AAPL  583948769961648128  ...           1  [0.39781833, 0.6021817]\n",
              "2         AAPL  583950963590897665  ...           1  [0.09492045, 0.9050796]\n",
              "3         AAPL  583952666491019264  ...           1  [0.40755036, 0.5924496]\n",
              "4         AAPL  583963546490404864  ...           1     [0.424042, 0.575958]\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_output.to_csv('tweets_combined_sentiment_output.csv',index=False)"
      ],
      "metadata": {
        "id": "ZL1UOClk0SaW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "BERT-Sentiment Based Method.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}